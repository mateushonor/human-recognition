import cv2
from ultralytics import YOLO
import os
import math

# model
model = YOLO("yolo-Weights/yolov8n.pt")

# object classes
classNames = ["person"]  # Supondo que 'person' é índice 0

USERNAME = 'Honor'
PASSWORD = 'Mateus2449'
IP = '192.168.100.158'
PORT = '554'

os.environ["OPENCV_FFMPEG_CAPTURE_OPTION"] = "rtsp_transport;udp"

URL = f'rtsp://{USERNAME}:{PASSWORD}@{IP}:{PORT}/onvif1'

cap = cv2.VideoCapture(URL, cv2.CAP_FFMPEG)

while True:
    ret, frame = cap.read()
   
    
    results = model(frame, stream=True)

    for r in results:
        boxes = r.boxes
        for box in boxes:
            # class name
            cls = int(box.cls[0])
            
            # Verifica se a classe detectada é 'person'
            if cls == 0:  # 0 é o índice para 'person' em classNames
                # bounding box
                x1, y1, x2, y2 = map(int, box.xyxy[0])

                # desenha o retângulo no frame
                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)

                # confiança
                confidence = math.ceil((box.conf[0] * 100)) / 100
                print("Confidence --->", confidence)

                # Detalhes do objeto
                org = (x1, y1)
                font = cv2.FONT_HERSHEY_SIMPLEX
                fontScale = 1
                color = (255, 0, 0)
                thickness = 2
                cv2.putText(frame, f'{classNames[cls]} {confidence}', org, font, fontScale, color, thickness)
    
    # Exibe o frame resultante
    cv2.imshow('VIDEO', frame)
    
    # Pressione 'q' para sair
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Libera o objeto de captura e fecha as janelas
cap.release()
cv2.destroyAllWindows()

        while True:
            start_time = time.time()
            ret, frame = cap.read()
            if not ret:
                print(f"Frame não foi recebido corretamente na câmera {camera_name}")
                # Pode optar por continuar tentando ler novos frames ou sair do loop
                continue  # Pula para a próxima iteração do loop

            # Como o frame foi lido com sucesso, agora podemos redimensioná-lo
            frame_resized = cv2.resize(frame, (640, 640))
            (rects, weights) = hog.detectMultiScale(frame_resized, winStride=(4, 4), padding=(8, 8), scale=1.05)

            if len(rects) > 0:
                results = model(frame_resized, stream=True)

                for r in results:
                    boxes = r.boxes
                    for box in boxes:
                        if int(box.cls[0]) == 0:  # Se a classe detectada é 'person'
                            x1, y1, x2, y2 = map(int, [box.xyxy[0][0] * frame.shape[1] / 640,
                                                       box.xyxy[0][1] * frame.shape[0] / 640,
                                                       box.xyxy[0][2] * frame.shape[1] / 640,
                                                       box.xyxy[0][3] * frame.shape[0] / 640])
                            print(f"{camera_name}: Pessoa detectada em [{x1}, {y1}, {x2}, {y2}]")

            time.sleep(max(1.0 / 30 - (time.time() - start_time), 0))

    finally:
        cap.release()
        cv2.destroyAllWindows()